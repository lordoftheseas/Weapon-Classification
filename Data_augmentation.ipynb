{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9ba0f8e-6b8e-4d7b-91e5-b5bef1668370",
   "metadata": {},
   "source": [
    "# CSE 455 WEAPON CLASSIFICATION - DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11643542-b4a2-44a4-bd4d-91cc5f226cb5",
   "metadata": {},
   "source": [
    "# Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "016ff0a6-44f7-45dd-8495-f886fac44a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "# import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ColorJitter, RandomGrayscale, Lambda, GaussianBlur, RandomPosterize\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ae979f-75cf-41df-9940-99943416bca5",
   "metadata": {},
   "source": [
    "# Data Augmentation (Transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2798919f-0a1e-4a43-a0d3-53cdd954f81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please change the location to the dataset we are using from the \"Weapon-Classification/Dataset/images\"\n",
    "# Image data generator for augmentation\n",
    "generate_data = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Input and output directories\n",
    "image_dir = \"Dataset/small augment data\"\n",
    "output_dir = \"Dataset/transformed augmented data\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop through images in the input directory\n",
    "for f in os.listdir(image_dir):\n",
    "    if f.lower().endswith(('jpg', 'png', 'jpeg')):\n",
    "        img_path = os.path.join(image_dir, f)  # Combine directory and filename\n",
    "        try:\n",
    "            # Load the image and preprocess\n",
    "            img = load_img(img_path)  # Load the image\n",
    "            x = img_to_array(img)    # Convert image to numpy array\n",
    "            x = x.reshape((1,) + x.shape)  # Add batch dimension\n",
    "\n",
    "            i = 0\n",
    "            for batch in generate_data.flow(x, batch_size=1, save_to_dir=output_dir, save_prefix='aug', save_format='jpeg'):\n",
    "                i += 1\n",
    "                if i > 20:  # Generate up to 20 augmented images per input image (can be altered based on what we will need)\n",
    "                    break\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {f}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8f5079-cb36-42df-9fac-32445ac488a6",
   "metadata": {},
   "source": [
    "# Random Erasing based Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fb9e160-7cba-4687-b96e-64d8fafe9c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please change the location to the dataset we are using from the \"Weapon-Classification/Dataset/images\"\n",
    "image_dir = \"Dataset/small augment data\"\n",
    "output_dir = \"Dataset/random erased augmented data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# transformation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=1, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False),\n",
    "    transforms.ToPILImage()\n",
    "])\n",
    "\n",
    "# Augment images and save to output directory\n",
    "for f in os.listdir(image_dir):\n",
    "    if f.lower().endswith(('jpg', 'png', 'jpeg')):\n",
    "        img_path = os.path.join(image_dir, f)\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            # Convert RGBA to RGB for saving as JPEG (PS: Don't delete this or we will lose datasets that are png)\n",
    "            if img.mode == 'RGBA':\n",
    "                img = img.convert('RGB')\n",
    "                \n",
    "            # save four different variation of images\n",
    "            for i in range(4):\n",
    "                random_erased_augmented_image = transform(img)\n",
    "                output_path = os.path.join(output_dir, f\"{os.path.splitext(f)[0]}_{i+1}.jpeg\") # save in the output directory\n",
    "                random_erased_augmented_image.save(output_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {f}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae87671c-e181-4237-b615-dc45a9fbddd0",
   "metadata": {},
   "source": [
    "# Color Transformation based Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d9c9785-c87e-4ed7-85e7-40a2353f65ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please change the location to the dataset we are using from the \"Weapon-Classification/Dataset/images\"\n",
    "\n",
    "# For Classification Tasks (Pre-trained Models)\n",
    "# transform = transforms.Compose([\n",
    "# transforms.RandomHorizontalFlip(),\n",
    "# transforms.PILToTensor(),\n",
    "# transforms.ConvertImageDtype(torch.float),\n",
    "# transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "# transforms.RandomErasing(),\n",
    "# ])\n",
    "\n",
    "\"\"\"\n",
    "PS: The pipeline above is for flipping and also remvoing parts of images from the augmented images but for now its just normalized color transformed image.\n",
    "Below are more ways to perform color transformation.\n",
    "\"\"\"\n",
    "# Color Jittering: It randomly changes the brightness, contrast, saturation, or hue of the image to simulate varying lighting conditions and camera settings.\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),  # Randomly adjust color properties\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# Random Grayscale Conversion: It converts the image to grayscale with a given probability which makes the model more robust to images with reduced or missing color information.\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.RandomGrayscale(p=0.2),  # 20% chance to convert to grayscale\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# Gamma Correction: It adjusts the gamma of an image to make it appear brighter or darker to simulate overexposed or underexposed images.\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     Lambda(lambda img: img.point(lambda x: x ** 0.8)),  # Apply gamma correction\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# Hue Rotation: It rotates the hue channel of the image which simulates images taken under different light sources (e.g., daylight vs. fluorescent lighting).\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ColorJitter(hue=0.3),  # Rotate hue randomly\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# Gaussian Blur: It applies a Gaussian blur filter to the image which simulates out-of-focus images or motion blur.\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 2.0)),  # Randomly blur the image\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "#Posterization: It reduces the number of bits used for each color channel, creating a \"posterized\" effect that simulates compression artifacts or low-quality images.\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.RandomPosterize(bits=4, p=0.5),  # Reduce to 4 bits with a 50% chance\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "image_dir = \"Dataset/small augment data\"\n",
    "output_dir = \"Dataset/augmented data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# transformation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.PILToTensor(),               # Convert image to tensor\n",
    "    transforms.ConvertImageDtype(torch.float),  # Scale to [0, 1]\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),  # Normalize\n",
    "])\n",
    "\n",
    "# Augment images and save to output directory\n",
    "for f in os.listdir(image_dir):\n",
    "    if f.lower().endswith(('jpg', 'png', 'jpeg')):\n",
    "        img_path = os.path.join(image_dir, f)\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            # Convert RGBA to RGB for saving as JPEG\n",
    "            if img.mode == 'RGBA':\n",
    "                img = img.convert('RGB')\n",
    "            augmented_img_tensor = transform(img)\n",
    "            augmented_img = transforms.ToPILImage()(augmented_img_tensor)\n",
    "            # Save the augmented image\n",
    "            output_path = os.path.join(output_dir, f\"{os.path.splitext(f)[0]}_aug_{i+1}.jpeg\")\n",
    "            augmented_img.save(output_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {f}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bee",
   "language": "python",
   "name": "bee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
