{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9ba0f8e-6b8e-4d7b-91e5-b5bef1668370",
   "metadata": {},
   "source": [
    "# CSE 455 WEAPON CLASSIFICATION - DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11643542-b4a2-44a4-bd4d-91cc5f226cb5",
   "metadata": {},
   "source": [
    "# Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016ff0a6-44f7-45dd-8495-f886fac44a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ColorJitter, RandomGrayscale, Lambda, GaussianBlur, RandomPosterize\n",
    "from PIL import Image\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ae979f-75cf-41df-9940-99943416bca5",
   "metadata": {},
   "source": [
    "# Data Augmentation (Transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2798919f-0a1e-4a43-a0d3-53cdd954f81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please change the location to the dataset we are using from the \"Weapon-Classification/Dataset/images\"\n",
    "# Image data generator for augmentation\n",
    "generate_data = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Input and output directories\n",
    "image_dir = \"Dataset/images\"  # Corrected path\n",
    "output_dir = \"Dataset/transformed augmented data\"  # Corrected path\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop through images in the input directory\n",
    "for f in os.listdir(image_dir):\n",
    "    if f.lower().endswith(('jpg', 'png', 'jpeg')):\n",
    "        img_path = os.path.join(image_dir, f)  # Combine directory and filename\n",
    "        try:\n",
    "            # Load the image and preprocess\n",
    "            img = load_img(img_path)  # Load the image\n",
    "            x = img_to_array(img)     # Convert image to numpy array\n",
    "            x = x.reshape((1,) + x.shape)  # Add batch dimension\n",
    "\n",
    "            # Extract the part before the first underscore to use as a subfolder name\n",
    "            subfolder_name = f.split('_')[0]\n",
    "            subfolder_path = os.path.join(output_dir, subfolder_name)\n",
    "\n",
    "            # Create subfolder if it doesn't exist\n",
    "            os.makedirs(subfolder_path, exist_ok=True)\n",
    "\n",
    "            i = 0\n",
    "            for batch in generate_data.flow(x, batch_size=1, save_to_dir=subfolder_path, save_prefix= subfolder_name, save_format='jpeg'):\n",
    "                i += 1\n",
    "                if i > 4:  # Generate up to 4 augmented images per input image\n",
    "                    break\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {f}: {e}\")\n",
    "# Cite: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8f5079-cb36-42df-9fac-32445ac488a6",
   "metadata": {},
   "source": [
    "# Random Erasing based Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb9e160-7cba-4687-b96e-64d8fafe9c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please change the location to the dataset we are using from the \"Weapon-Classification/Dataset/images\"\n",
    "\n",
    "# Define the paths\n",
    "image_dir = \"Dataset/images\"  # Corrected path\n",
    "output_dir = \"Dataset/random erased augmented data\"  # Corrected path\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Transformation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=1, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False),\n",
    "    transforms.ToPILImage()\n",
    "])\n",
    "\n",
    "# Augment images and save to output directory\n",
    "for f in os.listdir(image_dir):\n",
    "    if f.lower().endswith(('jpg', 'png', 'jpeg')):\n",
    "        img_path = os.path.join(image_dir, f)\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            # Convert RGBA to RGB for saving as JPEG (PS: Don't delete this or we will lose datasets that are png)\n",
    "            if img.mode == 'RGBA':\n",
    "                img = img.convert('RGB')\n",
    "            \n",
    "            # Extract the part before the first underscore to use as a subfolder name\n",
    "            subfolder_name = f.split('_')[0]\n",
    "            subfolder_path = os.path.join(output_dir, subfolder_name)\n",
    "\n",
    "            # Create subfolder if it doesn't exist\n",
    "            os.makedirs(subfolder_path, exist_ok=True)\n",
    "            \n",
    "            # Save four different variations of images in the subfolder\n",
    "            for i in range(4):\n",
    "                random_erased_augmented_image = transform(img)\n",
    "                output_path = os.path.join(subfolder_path, f\"{os.path.splitext(f)[0]}_{i+1}.jpeg\")\n",
    "                random_erased_augmented_image.save(output_path, 'JPEG')  # Save as JPEG\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {f}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae87671c-e181-4237-b615-dc45a9fbddd0",
   "metadata": {},
   "source": [
    "# Color Transformation based Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9c9785-c87e-4ed7-85e7-40a2353f65ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please change the location to the dataset we are using from the \"Weapon-Classification/Dataset/images\"\n",
    "\n",
    "# For Classification Tasks (Pre-trained Models)\n",
    "# transform = transforms.Compose([\n",
    "# transforms.RandomHorizontalFlip(),\n",
    "# transforms.PILToTensor(),\n",
    "# transforms.ConvertImageDtype(torch.float),\n",
    "# transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "# transforms.RandomErasing(),\n",
    "# ])\n",
    "\n",
    "\"\"\"\n",
    "PS: The pipeline above is for flipping and also remvoing parts of images from the augmented images but for now its just normalized color transformed image.\n",
    "Below are more ways to perform color transformation.\n",
    "\"\"\"\n",
    "# Color Jittering: It randomly changes the brightness, contrast, saturation, or hue of the image to simulate varying lighting conditions and camera settings.\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),  # Randomly adjust color properties\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# Random Grayscale Conversion: It converts the image to grayscale with a given probability which makes the model more robust to images with reduced or missing color information.\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.RandomGrayscale(p=0.2),  # 20% chance to convert to grayscale\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# Gamma Correction: It adjusts the gamma of an image to make it appear brighter or darker to simulate overexposed or underexposed images.\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     Lambda(lambda img: img.point(lambda x: x ** 0.8)),  # Apply gamma correction\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# Hue Rotation: It rotates the hue channel of the image which simulates images taken under different light sources (e.g., daylight vs. fluorescent lighting).\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ColorJitter(hue=0.3),  # Rotate hue randomly\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# Gaussian Blur: It applies a Gaussian blur filter to the image which simulates out-of-focus images or motion blur.\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 2.0)),  # Randomly blur the image\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "#Posterization: It reduces the number of bits used for each color channel, creating a \"posterized\" effect that simulates compression artifacts or low-quality images.\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.RandomPosterize(bits=4, p=0.5),  # Reduce to 4 bits with a 50% chance\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# image_dir = \"Dataset/small augment data\"\n",
    "# output_dir = \"Dataset/augmented data\"\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # transformation pipeline\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.PILToTensor(),               # Convert image to tensor\n",
    "#     transforms.ConvertImageDtype(torch.float),  # Scale to [0, 1]\n",
    "#     transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),  # Normalize\n",
    "# ])\n",
    "\n",
    "# # Augment images and save to output directory\n",
    "# for f in os.listdir(image_dir):\n",
    "#     if f.lower().endswith(('jpg', 'png', 'jpeg')):\n",
    "#         img_path = os.path.join(image_dir, f)\n",
    "#         try:\n",
    "#             img = Image.open(img_path)\n",
    "#             # Convert RGBA to RGB for saving as JPEG\n",
    "#             if img.mode == 'RGBA':\n",
    "#                 img = img.convert('RGB')\n",
    "#             augmented_img_tensor = transform(img)\n",
    "#             augmented_img = transforms.ToPILImage()(augmented_img_tensor)\n",
    "#             # Save the augmented image\n",
    "#             output_path = os.path.join(output_dir, f\"{os.path.splitext(f)[0]}_aug_{i+1}.jpeg\")\n",
    "#             augmented_img.save(output_path)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error processing file {f}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1361c7e-b039-4bee-bab5-ce8049ac773a",
   "metadata": {},
   "source": [
    "# Mosaic Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31dd25a-a537-43e1-b03c-4ee908cd6c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mosaic_augmentation_with_test(background_picture_for_mosaic, main_data_picture, output_path, grid_size=2, image_size=(150, 150), repetitions=3):\n",
    "    # Get all dataset and test dataset image paths\n",
    "    dataset_images = []\n",
    "    for img in os.listdir(background_picture_for_mosaic):\n",
    "        if img.endswith(('jpg', 'png', 'jpeg')):\n",
    "            dataset_images.append(os.path.join(background_picture_for_mosaic, img))\n",
    "\n",
    "    test_images = []\n",
    "    for img in os.listdir(main_data_picture):\n",
    "        if img.endswith(('jpg', 'png', 'jpeg')):\n",
    "            test_images.append(os.path.join(main_data_picture, img))\n",
    "    \n",
    "    random.shuffle(dataset_images)\n",
    "    \n",
    "    test_index = 0\n",
    "    \n",
    "    # Mosaic creation loop\n",
    "    while test_index < len(test_images):\n",
    "        # Select the next test image (sequentially)\n",
    "        test_image = test_images[test_index]\n",
    "        test_index += 1\n",
    "        \n",
    "        # Load and resize the test image based on given image_size\n",
    "        test_image_resized = Image.open(test_image).resize(image_size)\n",
    "\n",
    "        # Convert to RGB (JPEG format doesn't support transparency)\n",
    "        if test_image_resized.mode in ('RGBA', 'P'):\n",
    "            test_image_resized = test_image_resized.convert('RGB')\n",
    "\n",
    "        # Extract the name before the first \"_\" in the test image path\n",
    "        test_image_name = os.path.basename(test_image)\n",
    "        base_name = test_image_name.split(\"_\")[0]\n",
    "        \n",
    "        # Create subfolder for the base name (before the first \"_\")\n",
    "        subfolder_path = os.path.join(output_path, base_name)\n",
    "        os.makedirs(subfolder_path, exist_ok=True)\n",
    "        \n",
    "        for rep in range(repetitions):  # Loop for three repetitions\n",
    "            # Select 3 random images from the dataset\n",
    "            selected_dataset_images = random.sample(dataset_images, 3)\n",
    "            \n",
    "            # Load and resize images based on given image_size\n",
    "            images = []\n",
    "            for img in selected_dataset_images:\n",
    "                resized_image = Image.open(img).resize(image_size)\n",
    "                # Convert to RGB (JPEG format doesn't support transparency)\n",
    "                if resized_image.mode in ('RGBA', 'P'):\n",
    "                    resized_image = resized_image.convert('RGB')\n",
    "                images.append(resized_image)\n",
    "            \n",
    "            images.append(test_image_resized)  # Add the test image to the list\n",
    "            random.shuffle(images)  # Shuffle images to ensure random placement in the grid\n",
    "            \n",
    "            # Create a blank canvas for the mosaic\n",
    "            mosaic_size = (grid_size * image_size[0], grid_size * image_size[1])\n",
    "            mosaic = Image.new('RGB', mosaic_size, (155, 155, 155))  # Background color set to gray\n",
    "            \n",
    "            # Paste shuffled images into the grid in a row-by-row manner\n",
    "            img_index = 0\n",
    "            for i in range(grid_size):  # For each row (we have 2 rows)\n",
    "                for j in range(grid_size):  # For each column in the row\n",
    "                    if img_index < len(images):\n",
    "                        # Place the image at the calculated position\n",
    "                        mosaic.paste(images[img_index], (j * image_size[0], i * image_size[1]))\n",
    "                        img_index += 1\n",
    "            \n",
    "            # Save the mosaic as JPEG in the subfolder with the base name from the test image and repetition count\n",
    "            output_file = os.path.join(subfolder_path, f'{base_name}_{test_index}_{rep + 1}.jpeg')  # Saving as JPEG\n",
    "            mosaic.save(output_file, 'JPEG')\n",
    "\n",
    "# Example usage\n",
    "background_picture_for_mosaic = \"Dataset/data\"        # Path to your dataset of images\n",
    "main_data_picture = \"Dataset/Images\"   # Path to your test dataset of images\n",
    "output_path = \"Dataset/output mosaic augmentation\"          # Path to save the mosaic images\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "mosaic_augmentation_with_test(background_picture_for_mosaic, main_data_picture, output_path)\n",
    "\n",
    "# citation; https://www.kaggle.com/datasets/pankajkumar2002/random-image-sample-dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bee",
   "language": "python",
   "name": "bee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
