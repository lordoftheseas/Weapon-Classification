{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9ba0f8e-6b8e-4d7b-91e5-b5bef1668370",
   "metadata": {},
   "source": [
    "# CSE 455 WEAPON CLASSIFICATION - DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11643542-b4a2-44a4-bd4d-91cc5f226cb5",
   "metadata": {},
   "source": [
    "# Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "016ff0a6-44f7-45dd-8495-f886fac44a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ColorJitter, RandomGrayscale, Lambda, GaussianBlur, RandomPosterize\n",
    "from PIL import Image\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ae979f-75cf-41df-9940-99943416bca5",
   "metadata": {},
   "source": [
    "# Data Augmentation (Transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2798919f-0a1e-4a43-a0d3-53cdd954f81f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(subfolder_path, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     37\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 38\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgenerate_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msubfolder_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjpeg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Generate up to 4 augmented images per input image\u001b[39;49;00m\n",
      "File \u001b[1;32m~\\tfod\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:112\u001b[0m, in \u001b[0;36mIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    109\u001b[0m     index_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_generator)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# The transformation of images is not under thread lock\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# so it can be done in parallel\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_batches_of_transformed_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_array\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\tfod\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:654\u001b[0m, in \u001b[0;36mNumpyArrayIterator._get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    652\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx[j]\n\u001b[0;32m    653\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_data_generator\u001b[38;5;241m.\u001b[39mget_random_transform(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 654\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_data_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    657\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_data_generator\u001b[38;5;241m.\u001b[39mstandardize(x)\n\u001b[0;32m    658\u001b[0m batch_x[i] \u001b[38;5;241m=\u001b[39m x\n",
      "File \u001b[1;32m~\\tfod\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1413\u001b[0m, in \u001b[0;36mImageDataGenerator.apply_transform\u001b[1;34m(self, x, transform_parameters)\u001b[0m\n\u001b[0;32m   1410\u001b[0m img_col_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol_axis \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1411\u001b[0m img_channel_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannel_axis \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1413\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mapply_affine_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtheta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1419\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_row_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcol_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_col_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchannel_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_channel_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1426\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1427\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transform_parameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel_shift_intensity\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1430\u001b[0m     x \u001b[38;5;241m=\u001b[39m apply_channel_shift(\n\u001b[0;32m   1431\u001b[0m         x,\n\u001b[0;32m   1432\u001b[0m         transform_parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel_shift_intensity\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1433\u001b[0m         img_channel_axis,\n\u001b[0;32m   1434\u001b[0m     )\n",
      "File \u001b[1;32m~\\tfod\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1879\u001b[0m, in \u001b[0;36mapply_affine_transform\u001b[1;34m(x, theta, tx, ty, shear, zx, zy, row_axis, col_axis, channel_axis, fill_mode, cval, order)\u001b[0m\n\u001b[0;32m   1876\u001b[0m final_affine_matrix \u001b[38;5;241m=\u001b[39m transform_matrix[:\u001b[38;5;241m2\u001b[39m, :\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m   1877\u001b[0m final_offset \u001b[38;5;241m=\u001b[39m transform_matrix[:\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m-> 1879\u001b[0m channel_images \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[0;32m   1880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maffine_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_channel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfinal_affine_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfinal_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx_channel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1890\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(channel_images, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1891\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrollaxis(x, \u001b[38;5;241m0\u001b[39m, channel_axis \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\tfod\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1880\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1876\u001b[0m final_affine_matrix \u001b[38;5;241m=\u001b[39m transform_matrix[:\u001b[38;5;241m2\u001b[39m, :\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m   1877\u001b[0m final_offset \u001b[38;5;241m=\u001b[39m transform_matrix[:\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m   1879\u001b[0m channel_images \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m-> 1880\u001b[0m     \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maffine_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_channel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfinal_affine_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfinal_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1888\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x_channel \u001b[38;5;129;01min\u001b[39;00m x\n\u001b[0;32m   1889\u001b[0m ]\n\u001b[0;32m   1890\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(channel_images, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1891\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrollaxis(x, \u001b[38;5;241m0\u001b[39m, channel_axis \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\tfod\\Lib\\site-packages\\scipy\\ndimage\\_interpolation.py:626\u001b[0m, in \u001b[0;36maffine_transform\u001b[1;34m(input, matrix, offset, output_shape, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[0;32m    623\u001b[0m     _nd_image\u001b[38;5;241m.\u001b[39mzoom_shift(filtered, matrix, offset\u001b[38;5;241m/\u001b[39mmatrix, output, order,\n\u001b[0;32m    624\u001b[0m                          mode, cval, npad, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 626\u001b[0m     \u001b[43m_nd_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeometric_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Please change the location to the dataset we are using from the \"Weapon-Classification/Dataset/images\"\n",
    "# Image data generator for augmentation\n",
    "generate_data = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Input and output directories\n",
    "image_dir = \"Dataset/images\"  # Corrected path\n",
    "output_dir = \"Dataset/transformed augmented data\"  # Corrected path\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop through images in the input directory\n",
    "for f in os.listdir(image_dir):\n",
    "    if f.lower().endswith(('jpg', 'png', 'jpeg')):\n",
    "        img_path = os.path.join(image_dir, f)  # Combine directory and filename\n",
    "        try:\n",
    "            # Load the image and preprocess\n",
    "            img = load_img(img_path)  # Load the image\n",
    "            x = img_to_array(img)     # Convert image to numpy array\n",
    "            x = x.reshape((1,) + x.shape)  # Add batch dimension\n",
    "\n",
    "            # Extract the part before the first underscore to use as a subfolder name\n",
    "            subfolder_name = f.split('_')[0]\n",
    "            subfolder_path = os.path.join(output_dir, subfolder_name)\n",
    "\n",
    "            # Create subfolder if it doesn't exist\n",
    "            os.makedirs(subfolder_path, exist_ok=True)\n",
    "\n",
    "            i = 0\n",
    "            for batch in generate_data.flow(x, batch_size=1, save_to_dir=subfolder_path, save_prefix= subfolder_name, save_format='jpeg'):\n",
    "                i += 1\n",
    "                if i > 4:  # Generate up to 4 augmented images per input image\n",
    "                    break\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {f}: {e}\")\n",
    "# Cite: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8f5079-cb36-42df-9fac-32445ac488a6",
   "metadata": {},
   "source": [
    "# Random Erasing based Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fb9e160-7cba-4687-b96e-64d8fafe9c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please change the location to the dataset we are using from the \"Weapon-Classification/Dataset/images\"\n",
    "\n",
    "# Define the paths\n",
    "image_dir = \"Dataset/images\"  # Corrected path\n",
    "output_dir = \"Dataset/random erased augmented data\"  # Corrected path\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Transformation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=1, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False),\n",
    "    transforms.ToPILImage()\n",
    "])\n",
    "\n",
    "# Augment images and save to output directory\n",
    "for f in os.listdir(image_dir):\n",
    "    if f.lower().endswith(('jpg', 'png', 'jpeg')):\n",
    "        img_path = os.path.join(image_dir, f)\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            # Convert RGBA to RGB for saving as JPEG (PS: Don't delete this or we will lose datasets that are png)\n",
    "            if img.mode == 'RGBA':\n",
    "                img = img.convert('RGB')\n",
    "            \n",
    "            # Extract the part before the first underscore to use as a subfolder name\n",
    "            subfolder_name = f.split('_')[0]\n",
    "            subfolder_path = os.path.join(output_dir, subfolder_name)\n",
    "\n",
    "            # Create subfolder if it doesn't exist\n",
    "            os.makedirs(subfolder_path, exist_ok=True)\n",
    "            \n",
    "            # Save four different variations of images in the subfolder\n",
    "            for i in range(4):\n",
    "                random_erased_augmented_image = transform(img)\n",
    "                output_path = os.path.join(subfolder_path, f\"{os.path.splitext(f)[0]}_{i+1}.jpeg\")\n",
    "                random_erased_augmented_image.save(output_path, 'JPEG')  # Save as JPEG\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {f}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae87671c-e181-4237-b615-dc45a9fbddd0",
   "metadata": {},
   "source": [
    "# Color Transformation based Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d9c9785-c87e-4ed7-85e7-40a2353f65ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPS: The pipeline above is for flipping and also remvoing parts of images from the augmented images but for now its just normalized color transformed image.\\nBelow are more ways to perform color transformation.\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please change the location to the dataset we are using from the \"Weapon-Classification/Dataset/images\"\n",
    "\n",
    "# For Classification Tasks (Pre-trained Models)\n",
    "# transform = transforms.Compose([\n",
    "# transforms.RandomHorizontalFlip(),\n",
    "# transforms.PILToTensor(),\n",
    "# transforms.ConvertImageDtype(torch.float),\n",
    "# transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "# transforms.RandomErasing(),\n",
    "# ])\n",
    "\n",
    "\"\"\"\n",
    "PS: The pipeline above is for flipping and also remvoing parts of images from the augmented images but for now its just normalized color transformed image.\n",
    "Below are more ways to perform color transformation.\n",
    "\"\"\"\n",
    "# Color Jittering: It randomly changes the brightness, contrast, saturation, or hue of the image to simulate varying lighting conditions and camera settings.\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),  # Randomly adjust color properties\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# Random Grayscale Conversion: It converts the image to grayscale with a given probability which makes the model more robust to images with reduced or missing color information.\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.RandomGrayscale(p=0.2),  # 20% chance to convert to grayscale\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# Gamma Correction: It adjusts the gamma of an image to make it appear brighter or darker to simulate overexposed or underexposed images.\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     Lambda(lambda img: img.point(lambda x: x ** 0.8)),  # Apply gamma correction\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# Hue Rotation: It rotates the hue channel of the image which simulates images taken under different light sources (e.g., daylight vs. fluorescent lighting).\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ColorJitter(hue=0.3),  # Rotate hue randomly\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# Gaussian Blur: It applies a Gaussian blur filter to the image which simulates out-of-focus images or motion blur.\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 2.0)),  # Randomly blur the image\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "#Posterization: It reduces the number of bits used for each color channel, creating a \"posterized\" effect that simulates compression artifacts or low-quality images.\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.RandomPosterize(bits=4, p=0.5),  # Reduce to 4 bits with a 50% chance\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# image_dir = \"Dataset/small augment data\"\n",
    "# output_dir = \"Dataset/augmented data\"\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # transformation pipeline\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.PILToTensor(),               # Convert image to tensor\n",
    "#     transforms.ConvertImageDtype(torch.float),  # Scale to [0, 1]\n",
    "#     transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),  # Normalize\n",
    "# ])\n",
    "\n",
    "# # Augment images and save to output directory\n",
    "# for f in os.listdir(image_dir):\n",
    "#     if f.lower().endswith(('jpg', 'png', 'jpeg')):\n",
    "#         img_path = os.path.join(image_dir, f)\n",
    "#         try:\n",
    "#             img = Image.open(img_path)\n",
    "#             # Convert RGBA to RGB for saving as JPEG\n",
    "#             if img.mode == 'RGBA':\n",
    "#                 img = img.convert('RGB')\n",
    "#             augmented_img_tensor = transform(img)\n",
    "#             augmented_img = transforms.ToPILImage()(augmented_img_tensor)\n",
    "#             # Save the augmented image\n",
    "#             output_path = os.path.join(output_dir, f\"{os.path.splitext(f)[0]}_aug_{i+1}.jpeg\")\n",
    "#             augmented_img.save(output_path)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error processing file {f}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1361c7e-b039-4bee-bab5-ce8049ac773a",
   "metadata": {},
   "source": [
    "# Mosaic Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d31dd25a-a537-43e1-b03c-4ee908cd6c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bee\\tfod\\Lib\\site-packages\\PIL\\Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def mosaic_augmentation_with_test(background_picture_for_mosaic, main_data_picture, output_path, grid_size=2, image_size=(150, 150), repetitions=3):\n",
    "    # Get all dataset and test dataset image paths\n",
    "    dataset_images = []\n",
    "    for img in os.listdir(background_picture_for_mosaic):\n",
    "        if img.endswith(('jpg', 'png', 'jpeg')):\n",
    "            dataset_images.append(os.path.join(background_picture_for_mosaic, img))\n",
    "\n",
    "    test_images = []\n",
    "    for img in os.listdir(main_data_picture):\n",
    "        if img.endswith(('jpg', 'png', 'jpeg')):\n",
    "            test_images.append(os.path.join(main_data_picture, img))\n",
    "    \n",
    "    random.shuffle(dataset_images)\n",
    "    \n",
    "    test_index = 0\n",
    "    \n",
    "    # Mosaic creation loop\n",
    "    while test_index < len(test_images):\n",
    "        # Select the next test image (sequentially)\n",
    "        test_image = test_images[test_index]\n",
    "        test_index += 1\n",
    "        \n",
    "        # Load and resize the test image based on given image_size\n",
    "        test_image_resized = Image.open(test_image).resize(image_size)\n",
    "\n",
    "        # Convert to RGB (JPEG format doesn't support transparency)\n",
    "        if test_image_resized.mode in ('RGBA', 'P'):\n",
    "            test_image_resized = test_image_resized.convert('RGB')\n",
    "\n",
    "        # Extract the name before the first \"_\" in the test image path\n",
    "        test_image_name = os.path.basename(test_image)\n",
    "        base_name = test_image_name.split(\"_\")[0]\n",
    "        \n",
    "        # Create subfolder for the base name (before the first \"_\")\n",
    "        subfolder_path = os.path.join(output_path, base_name)\n",
    "        os.makedirs(subfolder_path, exist_ok=True)\n",
    "        \n",
    "        for rep in range(repetitions):  # Loop for three repetitions\n",
    "            # Select 3 random images from the dataset\n",
    "            selected_dataset_images = random.sample(dataset_images, 3)\n",
    "            \n",
    "            # Load and resize images based on given image_size\n",
    "            images = []\n",
    "            for img in selected_dataset_images:\n",
    "                resized_image = Image.open(img).resize(image_size)\n",
    "                # Convert to RGB (JPEG format doesn't support transparency)\n",
    "                if resized_image.mode in ('RGBA', 'P'):\n",
    "                    resized_image = resized_image.convert('RGB')\n",
    "                images.append(resized_image)\n",
    "            \n",
    "            images.append(test_image_resized)  # Add the test image to the list\n",
    "            random.shuffle(images)  # Shuffle images to ensure random placement in the grid\n",
    "            \n",
    "            # Create a blank canvas for the mosaic\n",
    "            mosaic_size = (grid_size * image_size[0], grid_size * image_size[1])\n",
    "            mosaic = Image.new('RGB', mosaic_size, (155, 155, 155))  # Background color set to gray\n",
    "            \n",
    "            # Paste shuffled images into the grid in a row-by-row manner\n",
    "            img_index = 0\n",
    "            for i in range(grid_size):  # For each row (we have 2 rows)\n",
    "                for j in range(grid_size):  # For each column in the row\n",
    "                    if img_index < len(images):\n",
    "                        # Place the image at the calculated position\n",
    "                        mosaic.paste(images[img_index], (j * image_size[0], i * image_size[1]))\n",
    "                        img_index += 1\n",
    "            \n",
    "            # Save the mosaic as JPEG in the subfolder with the base name from the test image and repetition count\n",
    "            output_file = os.path.join(subfolder_path, f'{base_name}_{test_index}_{rep + 1}.jpeg')  # Saving as JPEG\n",
    "            mosaic.save(output_file, 'JPEG')\n",
    "\n",
    "# Example usage\n",
    "background_picture_for_mosaic = \"Dataset/data\"        # Path to your dataset of images\n",
    "main_data_picture = \"Dataset/Images\"   # Path to your test dataset of images\n",
    "output_path = \"Dataset/output mosaic augmentation\"          # Path to save the mosaic images\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "mosaic_augmentation_with_test(background_picture_for_mosaic, main_data_picture, output_path)\n",
    "\n",
    "# citation; https://www.kaggle.com/datasets/pankajkumar2002/random-image-sample-dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bee",
   "language": "python",
   "name": "bee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
